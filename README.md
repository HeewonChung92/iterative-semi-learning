# iterative-semi-supervised-learning using softmax probability

For the classification problem in practice, one of the challenging issues is to obtain enough labeled data for training. Moreover, even if such labeled data has been sufficiently accumulated, most datasets often exhibit long-tailed distribution with heavy class imbalance. In order to alleviate those issues, semi-supervised learning using additional unlabeled data has been considered. However, as a matter of course, the accuracy is much lower than that from supervised learning. In this study, we propose  the semi-supervised learning algorithms, which iteratively corrects the labeling of the extra unlabeled data based on softmax probabilities. The results show that the proposed algorithms provide the accuracy as high as that from supervised learning. To validate the proposed algorithms, we tested on the two scenarios: with the balanced unlabeled dataset and with the imbalanced unlabeled dataset. Under both scenarios, our proposed semi-supervised learning algorithms provided the classification accuracy very close to that from the ideal supervised learning, where the unlabeled data is given 100% labeling accuracy.

